{
 "metadata": {
  "name": "",
  "signature": "sha256:20d03787ad59cc6b34d0c380b03709fc7e547acc1401229b970cd20fa75a31b8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture7/lecture_7_elementary_text_classification.pdf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lab3_url = \"http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture7/lecture_7_elementary_text_classification.pdf\"\n",
      "HTML(data=\"<iframe src='{0}' width=1000 height=1000></iframe>\".format(lab3_url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src='http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture7/lecture_7_elementary_text_classification.pdf' width=1000 height=1000></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<IPython.core.display.HTML at 0x7fad347dfb90>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.corpus import movie_reviews\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.github.com/nltk_data/\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dir(movie_reviews)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "['CorpusView',\n",
        " '_LazyCorpusLoader__args',\n",
        " '_LazyCorpusLoader__kwargs',\n",
        " '_LazyCorpusLoader__name',\n",
        " '_LazyCorpusLoader__reader_cls',\n",
        " '__class__',\n",
        " '__delattr__',\n",
        " '__dict__',\n",
        " '__doc__',\n",
        " '__format__',\n",
        " '__getattribute__',\n",
        " '__hash__',\n",
        " '__init__',\n",
        " '__module__',\n",
        " '__name__',\n",
        " '__new__',\n",
        " '__reduce__',\n",
        " '__reduce_ex__',\n",
        " '__repr__',\n",
        " '__setattr__',\n",
        " '__sizeof__',\n",
        " '__str__',\n",
        " '__subclasshook__',\n",
        " '__unicode__',\n",
        " '__weakref__',\n",
        " '_add',\n",
        " '_get_root',\n",
        " '_init',\n",
        " '_read_para_block',\n",
        " '_read_sent_block',\n",
        " '_read_word_block',\n",
        " '_resolve',\n",
        " 'abspath',\n",
        " 'abspaths',\n",
        " 'categories',\n",
        " 'encoding',\n",
        " 'ensure_loaded',\n",
        " 'fileids',\n",
        " 'open',\n",
        " 'paras',\n",
        " 'raw',\n",
        " 'readme',\n",
        " 'root',\n",
        " 'sents',\n",
        " 'unicode_repr',\n",
        " 'words']"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movie_reviews.categories()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'neg', u'pos']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(movie_reviews.fileids('neg')), len(movie_reviews.fileids('pos'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(1000, 1000)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movie_reviews.fileids('pos')[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "u'pos/cv000_29590.txt'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movie_reviews.words('pos/cv000_29590.txt')[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[u'films',\n",
        " u'adapted',\n",
        " u'from',\n",
        " u'comic',\n",
        " u'books',\n",
        " u'have',\n",
        " u'had',\n",
        " u'plenty',\n",
        " u'of',\n",
        " u'success',\n",
        " u',',\n",
        " u'whether',\n",
        " u'they',\n",
        " u\"'\",\n",
        " u're',\n",
        " u'about',\n",
        " u'superheroes',\n",
        " u'(',\n",
        " u'batman',\n",
        " u',']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "examples_in_code_url = \"http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture7/movie_reviews.py\"\n",
      "HTML(\"<iframe src='{0}' height=500 width=1000></iframe>\".format(examples_in_code_url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src='http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture7/movie_reviews.py' height=500 width=1000></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<IPython.core.display.HTML at 0x7fad11297090>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, random\n",
      "from nltk.corpus import movie_reviews\n",
      "\n",
      "print(movie_reviews.categories())\n",
      "\n",
      "documents = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
      "random.shuffle(documents)\n",
      "\n",
      "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
      "word_features = list(all_words.keys())[:2000] # note that this is different than wha'ts \n",
      "def document_features(document):\n",
      "    document_words = set(document)\n",
      "    features = {}\n",
      "    for word in word_features:\n",
      "        features['contains(%s)' % word] = (word in document_words)\n",
      "    return features\n",
      "\n",
      "\n",
      "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
      "train_set, test_set = featuresets[100:], featuresets[:100]\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "print(nltk.classify.accuracy(classifier, test_set))\n",
      "classifier.show_most_informative_features(5)\n",
      "\n",
      "def small_document_features(document):\n",
      "    document_words = set(document)\n",
      "    my_words = list['good','great','excellent','bad','terrible']\n",
      "    for word in my_words:\n",
      "        features['contains(%s)' % word] = (word in document_words)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'neg', u'pos']\n",
        "0.69"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Most Informative Features\n",
        "          contains(sans) = True              neg : pos    =      9.1 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    contains(mediocrity) = True              neg : pos    =      7.7 : 1.0\n",
        "     contains(dismissed) = True              pos : neg    =      6.9 : 1.0\n",
        "         contains(wires) = True              neg : pos    =      6.4 : 1.0\n",
        "   contains(overwhelmed) = True              pos : neg    =      6.3 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(documents), len(documents[0]), len(documents[100]), documents[0][1], documents[100][1], documents[1000][1], documents[999][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(2000, 2, 2, u'neg', u'pos', u'pos', u'neg')"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def small_document_features(document):\n",
      "    document_words = set(document)\n",
      "    my_words = ['good', 'great', 'excellent', 'bad', 'terrible']\n",
      "    features = {}\n",
      "    for word in my_words:\n",
      "        features ['contains(%s)' % word] = (word in document_words)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small_featuresets = [(small_document_features(d), c) for (d,c) in documents]\n",
      "train_set, test_set = small_featuresets[100:], small_featuresets[:100]\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "print(nltk.classify.accuracy(classifier, test_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.66\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}